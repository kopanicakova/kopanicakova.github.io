---
layout: archive
title: ""
permalink: /ANITI_chair/
author_profile: true
---

### <span style="color:rgb(199, 21, 133)">HAISLED: Hybridizing AI and Large-scale Simulations for
Engineering Design</span>

I serve as the Principal Investigator for the international HAISLED Chair at <a href="https://aniti.univ-toulouse.fr/"><span style="color:rgb(199, 21, 133)">ANITI<\span></a>.
<strong>Co-chairs:</strong> Michael Bauerheim (ISAE-Supaero Toulouse), Paul Novello (IRT Saint-Exupéry Toulouse)


#### <span style="color:rgb(199, 21, 133)">Abstract:</span>
Recently, scientific machine learning (SciML) has expanded the capabilities of traditional numerical approaches, by simplifying computational modeling and providing cost-effective surrogates.
However, SciML surrogates suffer from absence of the explicit error control, computationally intensive training phase, and the lack of reliability in practice. 
HAILSED aims to tackle these challenges by <br>
(1) developing novel types of SciML surrogates, the architecture of which incorporates  physical and geometric constraints explicitly, and whose validation error can be controlled <em> a posteriori</em>, <br>
(2) developing novel training algorithms, which leverage domain-decomposition-based approaches and utilize model parallelism,<\br>
(3) hybridizing SciML surrogates with state-of-the-art numerical solution methods, which will be achieved by developing AI-equipped nonlinear field-split and domain-decomposition-based preconditioning strategies. <br>
Successful realization of this project has a potential to pave the way towards efficient and error-controlled solution of large-scale multi-physics and multi-scale problems  by combining the efficiency of SciML surrogates with the accuracy and reliability of standard numerical approaches.




#### <span style="color:rgb(199, 21, 133)">Research objectives:</span>
<ul>
  <li>Approximation limits for SciML surrogates</li>
  <li>Incorporation of physical and geometric constraints into SciML architectures</li>
  <li>Domain decomposition algorithms that are robust to sub-sampling noise and can efficiently exploit the underlying structure of deep neural networks</li>
  <li>Globally convergent hybridization and error control of iterative methods with machine learning approaches</li>
</ul>



#### <span style="color:rgb(199, 21, 133)">Collaborations:</span>
<ul>
  <li><strong>IRT Saint Exupéry:</strong> Error bounds for SciML surrogates using the Lipschitz constant</li>
  <li><strong>Airbus, Vitesco, and Liebherr:</strong> Surrogate modeling for industrial design. Collaboration led by P. Novello</li>
  <li><strong>EPFL (Switzerland, group of P. Fua):</strong> Fully differentiable AI-based pipeline for rapid optimization. Collaboration led by M. Bauerheim</li>
  <li><strong>Sandia National Laboratories (USA, group of E. Cyr):</strong> Parallel learning algorithms for large-scale machine learning</li>
  <li><strong>KAUST/Università della Svizzera Italiana/UniDistance (Saudi Arabia/Switzerland, group of R. Krause):</strong> Parallel learning algorithms for large-scale machine learning</li>
</ul>




#### <span style="color:rgb(199, 21, 133)">Targeted scientific results:</span>
<ul>
  <li>Error control for SciML surrogates</li>
  <li>Efficient and parallel training of deep neural networks</li>
  <li>Efficient solution of large-scale, high-fidelity multiscale and multiphysics problems</li>
</ul>
